<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Prediction of boiling points using WikiData and Machine learning techniques</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="version.html">Used packages</a>
</li>
<li>
  <a href="raw.html">Code</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Prediction of boiling points using WikiData and Machine learning techniques</h1>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>This GitHub Page is a final product of assignment 2, requested by the course MSB1015 (Scientific Programming). The goal is to create a GitHub Page (notebook) for the following analysis. The boiling points of alkenes need to be predicted based on data from WikiData; Smiles are used to enrich the data using the rcdk package in R, afterward, machine learning is applied. See the <a href="https://github.com/Rrtk2/MSB1015-Assignment-2">GitHub repository</a> for more details.</p>
</div>
<div id="workflow" class="section level2">
<h2>Workflow</h2>
<p>Data extraction from wikidata (alkene name, smiles, boiling point).</p>
<p>Data expansion and cleanup (using rcdk).</p>
<p>Apply machine learing techniques using the expanded data, to predict boiling point (glm, plsr, randomForest).</p>
<p>Compare results.</p>
<div id="script-block-1-install-packages" class="section level4">
<h4>Script block 1: INSTALL PACKAGES</h4>
<pre class="r"><code>    # Install packages if needed and load, or just load packages
    if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE))
      install.packages(&quot;BiocManager&quot;, ask = F)

    # Insert all packages in requiredpackages
    requiredpackages &lt;-
      c(&quot;WikidataQueryServiceR&quot;,&quot;ggplot2&quot;,&quot;backports&quot;,&quot;rJava&quot;,&quot;rcdk&quot;,&quot;pls&quot;,&quot;randomForest&quot;,
      &quot;gplots&quot;,&quot;curl&quot;,&quot;data.table&quot;,&quot;caret&quot;,&quot;ggfortify&quot;,&quot;tidyverse&quot;)
        
    for (i in requiredpackages) {
        if (!requireNamespace(i, quietly = TRUE))
            BiocManager::install(i, ask = F, dependencies = c(&quot;Depends&quot;, &quot;Imports&quot;))
        require(as.character(i), character.only = TRUE)
        print(i)
    }</code></pre>
<pre><code>## Loading required package: WikidataQueryServiceR</code></pre>
<pre><code>## Warning: package &#39;WikidataQueryServiceR&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;WikidataQueryServiceR&quot;</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;ggplot2&quot;</code></pre>
<pre><code>## Loading required package: backports</code></pre>
<pre><code>## Warning: package &#39;backports&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;backports&quot;</code></pre>
<pre><code>## Loading required package: rJava</code></pre>
<pre><code>## Warning: package &#39;rJava&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;rJava&quot;</code></pre>
<pre><code>## Loading required package: rcdk</code></pre>
<pre><code>## Warning: package &#39;rcdk&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Loading required package: rcdklibs</code></pre>
<pre><code>## Warning: package &#39;rcdklibs&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;rcdk&quot;</code></pre>
<pre><code>## Loading required package: pls</code></pre>
<pre><code>## 
## Attaching package: &#39;pls&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     loadings</code></pre>
<pre><code>## [1] &quot;pls&quot;</code></pre>
<pre><code>## Loading required package: randomForest</code></pre>
<pre><code>## Warning: package &#39;randomForest&#39; was built under R version 3.5.3</code></pre>
<pre><code>## randomForest 4.6-14</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: &#39;randomForest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<pre><code>## [1] &quot;randomForest&quot;</code></pre>
<pre><code>## Loading required package: gplots</code></pre>
<pre><code>## Warning: package &#39;gplots&#39; was built under R version 3.5.3</code></pre>
<pre><code>## 
## Attaching package: &#39;gplots&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     lowess</code></pre>
<pre><code>## [1] &quot;gplots&quot;</code></pre>
<pre><code>## Loading required package: curl</code></pre>
<pre><code>## Warning: package &#39;curl&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;curl&quot;</code></pre>
<pre><code>## Loading required package: data.table</code></pre>
<pre><code>## Warning: package &#39;data.table&#39; was built under R version 3.5.3</code></pre>
<pre><code>## data.table 1.12.2 using 6 threads (see ?getDTthreads).  Latest news: r-datatable.com</code></pre>
<pre><code>## [1] &quot;data.table&quot;</code></pre>
<pre><code>## Loading required package: caret</code></pre>
<pre><code>## Warning: package &#39;caret&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:pls&#39;:
## 
##     R2</code></pre>
<pre><code>## [1] &quot;caret&quot;</code></pre>
<pre><code>## Loading required package: ggfortify</code></pre>
<pre><code>## Warning: package &#39;ggfortify&#39; was built under R version 3.5.3</code></pre>
<pre><code>## [1] &quot;ggfortify&quot;</code></pre>
<pre><code>## Loading required package: tidyverse</code></pre>
<pre><code>## Warning: package &#39;tidyverse&#39; was built under R version 3.5.3</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.2.1 --</code></pre>
<pre><code>## v tibble  2.1.3     v purrr   0.3.2
## v tidyr   1.0.0     v dplyr   0.8.3
## v readr   1.3.1     v stringr 1.4.0
## v tibble  2.1.3     v forcats 0.4.0</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;readr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;purrr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.5.3</code></pre>
<pre><code>## Warning: package &#39;forcats&#39; was built under R version 3.5.3</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::between()       masks data.table::between()
## x dplyr::combine()       masks randomForest::combine()
## x dplyr::filter()        masks stats::filter()
## x dplyr::first()         masks data.table::first()
## x dplyr::lag()           masks stats::lag()
## x dplyr::last()          masks data.table::last()
## x purrr::lift()          masks caret::lift()
## x randomForest::margin() masks ggplot2::margin()
## x dplyr::matches()       masks tidyr::matches(), rcdk::matches()
## x readr::parse_date()    masks curl::parse_date()
## x purrr::transpose()     masks data.table::transpose()</code></pre>
<pre><code>## [1] &quot;tidyverse&quot;</code></pre>
</div>
<div id="script-block-2-settings" class="section level4">
<h4>Script block 2: SETTINGS</h4>
<pre class="r"><code>    # General settings
    options(stringsAsFactors    = F)

    # Select 80% for train, 20% for test
    Randomfactor = 0.8
    linearAlkanesOnly = 0  # 1 = yes; 0 = no.

    # Setting seed to keep consistent results 
    set.seed(1)</code></pre>
</div>
<div id="script-block-3-functions" class="section level4">
<h4>Script block 3: FUNCTIONS</h4>
<pre class="r"><code>    # Root Mean Squared Error
    RMSE = function(yact, ypred){
      sqrt(mean((yact - ypred)^2))
    }

    # Mean Absolute Error 
    MAE = function(yact, ypred){
      mean(abs(yact - ypred))
    }</code></pre>
</div>
<div id="script-block-4-query-call" class="section level4">
<h4>Script block 4: QUERY CALL</h4>
<pre class="r"><code>    endpoint = &quot;https://query.wikidata.org/bigdata/namespace/wdq/sparql&quot;

    query = &#39;SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?CC WHERE {
      ?comp wdt:P31/wdt:P279* wd:Q41581 ;
            p:P2102 [
              ps:P2102 ?bp ;
              psv:P2102/wikibase:quantityUnit  ?bpUnit
            ] .
            ?comp wdt:P233 ?CC .
      SERVICE wikibase:label { bd:serviceParam wikibase:language &quot;[AUTO_LANGUAGE],en&quot;. }
    }
    &#39;

    dataObj = query_wikidata(query)</code></pre>
<pre><code>## 134 rows were returned by WDQS</code></pre>
</div>
<div id="script-block-5-boilingpoint-unit-conversion" class="section level4">
<h4>Script block 5: BOILINGPOINT UNIT CONVERSION</h4>
<pre class="r"><code>    #C to Kelvin:
    # 0°C + 273.15 = 273,15K
    idC = which(dataObj$bpUnitLabel==&quot;degree Celsius&quot;)
    for( i in 1:length(idC)){
        dataObj[idC[i],]$bp = (dataObj[idC[i],]$bp + 273.15)
        dataObj[idC[i],]$bpUnitLabel = &quot;kelvin&quot;
    }

    #F to Kelvin:
    # (0°F − 32) × 5/9 + 273.15 = 255,372K
    idF = which(dataObj$bpUnitLabel==&quot;degree Fahrenheit&quot;)
    for( i in 1:length(idF)){
        dataObj[idF[i],]$bp= (dataObj[idF[i],]$bp - 32) * (5/9) + 273.15
        dataObj[idF[i],]$bpUnitLabel = &quot;kelvin&quot;
    }

    #additional failsafe if other metrics than Celsius and Fahrenheit are added (other metrics are removed)
    dataObj = dataObj[which(dataObj$bpUnitLabel==&quot;kelvin&quot;),]

    # Make backup
    dataObjBACKUP = dataObj

    # Finalize data structure
    dataObj = data.frame(dataObjBACKUP$compLabel, dataObjBACKUP$bp, dataObjBACKUP$CC)
    names(dataObj) = c(&quot;Comp&quot;,&quot;bp&quot;,&quot;CC&quot;)</code></pre>
</div>
<div id="script-block-6-filters-and-outlier-handling" class="section level4">
<h4>Script block 6: FILTERS AND OUTLIER HANDLING</h4>
<pre class="r"><code>    if(linearAlkanesOnly == 1){
        dataObj = dataObj[-grep(pattern = &quot;\\(&quot;,x = dataObj$CC),]
    }

    # hexatriacontane 770.15 K (497 C); in wikidata under pressurised condition!
    dataObj$bp[dataObj$Comp==&quot;hexatriacontane&quot;] = 770.15

    # Dooctacontane 958.05 K (684.9 c); IN WIKIDATA AS 881.85 k
    dataObj$bp[dataObj$Comp==&quot;Dooctacontane&quot;] = 958.05</code></pre>
</div>
<div id="script-block-7-data-overview" class="section level4">
<h4>Script block 7: DATA OVERVIEW</h4>
<pre class="r"><code>    # Get a general idea of how the data looks; disregarding branch effects; amount of C in compound linked to BP
    CClength_crude = nchar(gsub(pattern = &quot;\\)&quot;,replacement = &quot;&quot;,x = gsub(pattern = &quot;\\(&quot;,replacement = &quot;&quot;,x = dataObj$CC)))
    plotCClength = CClength_crude[order(CClength_crude)]
    BPplot = dataObj$bp[order(CClength_crude)]

    # Should result in a exponential function-like graph
    plot(plotCClength,BPplot,main = &quot;Carbon - boilingpoint relation&quot;,xlab = &quot;Amount of carbon atoms in alkene&quot;,ylab = &quot;Boiling point (Kelvin)&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>    # Show how the data is distributed (focussing on bp)
    hist(dataObj$bp,breaks=20,main = &quot;Boiling point frequency distribution&quot;,xlab = &quot;Boiling point (Kelvin)&quot;,ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
</div>
<div id="script-block-8-data-enrichment" class="section level4">
<h4>Script block 8: DATA ENRICHMENT</h4>
<pre class="r"><code>    sp &lt;- get.smiles.parser()
    dc &lt;- get.desc.categories()

    for( i in 1:length(dataObj$CC)){

        # Get smiles from result query and add information
        molecule &lt;- parse.smiles(dataObj$CC[i])[[1]]
        convert.implicit.to.explicit(molecule)
        #formula &lt;- get.mol2formula(molecule,charge=0)


        # Store the found information
        #dataObj$formula[i] = {formula} # S4 object cannot be transferred nicely
        #dataObj$mass[i] = formula@mass
        #dataObj$string[i] = formula@string
        #dataObj$charge[i] = formula@charge

        # M/z values 
        #dataObj$isotopes[i] = {get.isotopes.pattern(formula,minAbund=0.1)}

        # Fingerprint? values
        #dataObj$fingerprint[i] = {get.fingerprint(molecule = molecule)}

        # Create a dataframe which contains all info possible to extract using the descriptors
        datafr = dataObj$Comp[i]
        for(o in 1:5){
            dn &lt;- get.desc.names(dc[o])
            datafr = cbind(datafr, eval.desc(molecule, dn))
        }
        
        # This is done now as it will break if descriptors change (amount)
        if(exists(&quot;mydata&quot;)){
            mydata[i,] = datafr
            }else{
            mydata = datafr
        }

    }

    # Make backup from data, easy for testing (resetting)
    mydataBACKUP = mydata
    mydata = mydataBACKUP

    # Remove names
    descs = mydata[,-1]</code></pre>
</div>
<div id="script-block-9-latent-variable-filter" class="section level4">
<h4>Script block 9: LATENT VARIABLE FILTER</h4>
<pre class="r"><code># Remove NAs n stuff
    descs &lt;- descs[, !apply(descs, 2, function(x) any(is.na(x)) )]
    descs &lt;- descs[, !apply( descs, 2, function(x) length(unique(x)) == 1 )]

    if(T){
        # Correlate the descriptors with the boiling point; if these are linked, they should add some info
        corMatrix = cor(descs , dataObj$bp)
        corMatrix = as.data.frame(corMatrix[order(abs(corMatrix),decreasing = T),])

        # select first 15 components:
        componentNames = rownames(corMatrix)[1:15]
        descs = descs[,match(colnames(descs), x = componentNames)]
    }

    # - BLOCKED - Old method, keepin this inside for further reference 
    if(F){
        mydata = mydataBACKUP
        descs = mydata[,-1]

        # crude way to extract &#39;important&#39; features based on correlation
        descs &lt;- descs[, !apply(descs, 2, function(x) any(is.na(x)) )]
        descs &lt;- descs[, !apply( descs, 2, function(x) length(unique(x)) == 1 )]
        r2 &lt;- which(cor(descs)^2 &gt; .9, arr.ind=TRUE) # when keeping this high, the prediction improves
        r2 &lt;- r2[ r2[,1] &gt; r2[,2] , ]
        descs &lt;- descs[, -unique(r2[,2])]
    }
    # - BLOCKED -

    # should contain nAtomLAC; the amount of c atoms
    if(!exists(&quot;descs$nAtomLAC&quot;)){

        descs = cbind(descs, mydata$nAtomLAC)
        names(descs)[dim(descs)[2]] = &quot;n&quot;
        }else{
        names(descs)[names(descs)==&quot;descs$nAtomLAC&quot;] = &quot;n&quot;
    }

    # Store resulting input file in my_data; as it is used everywhere
    my_data = descs

    # Finish prepare data
    # Add and define the &#39;to be predicted&#39; column
    n_col &lt;- ncol(my_data)
    BoilPoint = n_col+1
    my_data[,BoilPoint] = dataObj$bp
    names(my_data)[BoilPoint] = &#39;BoilPoint&#39;

    # Ordered data is required later
    my_data = my_data[order(my_data$BoilPoint),]</code></pre>
</div>
<div id="script-block-10-data-subsetting-for-machine-learning" class="section level4">
<h4>Script block 10: DATA SUBSETTING FOR MACHINE LEARNING</h4>
<pre class="r"><code>    # Define variables 
    sample.length = length(my_data[,1])

    # Higher probability to select lower (underrepresented) samples; 
    # improves range of model, increases fit and prediction power.
    # Ranges from 1 (select) to 0.5 (chance)
    sample.biasprob = 1 - 1:sample.length /max(sample.length )/2 

    # Make data objects
    samples.upper = sample(sample.length , floor(length(my_data[,1])*Randomfactor),prob = sample.biasprob ) #get all unique samples (not frequecies) and sample 80%
    #plot(samples.upper[order(samples.upper)])
    samples.total = (1:length(my_data[,1])) # all unique samples (not frequecies)
    samples.lowerl = samples.total[!samples.total %in% samples.upper]  #which samples are sampled

    # Subset data
    data.train = my_data[samples.upper,]#contains all upper 
    data.train = as.data.frame(data.train)
    data.test = my_data[samples.lowerl,]#contains all lower 
    data.test = as.data.frame(data.test)

    # Remove nas
    data.train=data.train[!is.na(data.train[,1]),]
    data.test=data.test[!is.na(data.test[,1]),]

    # Create standardized object
    xNN = data.train[,-(BoilPoint)]
    yNN = data.train[,BoilPoint]
    dat = data.frame(xNN, y = yNN)

    # Remove samples with in datasets n &lt; 1
    data.train = dat[dat$n&gt;0,]
    yactual.train = data.train$y
    data.test = data.test[data.test$n&gt;0,]
    yactual.test = data.test$BoilPoint</code></pre>
</div>
<div id="script-block-11-pls-model" class="section level4">
<h4>Script block 11: PLS MODEL</h4>
<pre class="r"><code>    # Define training control method; 10 - k - cross validation
    train_control &lt;- trainControl(method=&quot;cv&quot;, number=10)

    # Train the model
    model &lt;- train(y~., data=data.train, trControl=train_control, method=&quot;pls&quot;)

    # Find out what model is best
    print(model)</code></pre>
<pre><code>## Partial Least Squares 
## 
## 106 samples
##  16 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 96, 97, 96, 96, 94, 95, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  RMSE      Rsquared   MAE     
##   1      78.87058  0.9119517  68.48250
##   2      61.55186  0.9448577  48.80862
##   3      20.02921  0.9935239  15.35512
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was ncomp = 3.</code></pre>
<pre class="r"><code>    # Find out most important variables
    Varimportance = varImp(model)
    cat(paste(&quot;Best model fit with&quot;, model$bestTune, &quot;latent components \n&quot;))</code></pre>
<pre><code>## Best model fit with 3 latent components</code></pre>
<pre class="r"><code>    cat(paste(&quot;Latent components:&quot;,paste(rownames(Varimportance$importance)[order(decreasing = T,Varimportance$importance$Overall)][1:model$bestTune[1,]],collapse = &quot;, &quot;),&quot;\n&quot;))</code></pre>
<pre><code>## Latent components: VAdjMat, Kier1, khs.ssCH2</code></pre>
<pre class="r"><code>    plot(Varimportance, main=&quot;Varible importance in PLS model \n&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>    # Predict test set
    ypredCARET.pls.test &lt;- model %&gt;% predict(data.test)

    # Root mean squared error
    RMSE.pls.test = RMSE(yactual.test, ypredCARET.pls.test)
    RMSE.pls.test</code></pre>
<pre><code>## [1] 16.09627</code></pre>
<pre class="r"><code>    # Results in: 10.61

    # Mean absolute error
    MAE.pls.test = MAE(yactual.test, ypredCARET.pls.test)
    MAE.pls.test</code></pre>
<pre><code>## [1] 14.97591</code></pre>
<pre class="r"><code>    # Results in: 10.00

    # Plot ypred vs yactual of test data
    plot(yactual.test, ypredCARET.pls.test,
        xlab=&quot;Observed BP test set&quot;, ylab=&quot;Predicted BP test set&quot;,
        pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main=&quot;Prediction error test set (PLS model)&quot;)
        abline(0,1, col=&#39;red&#39;)
        text(200,ceiling(max(yNN)*1.1),paste(&quot;RMSE: &quot;,RMSE.pls.test))
        text(200,ceiling(max(yNN)*1.1)-50,paste(&quot;MAE: &quot;,MAE.pls.test))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<pre class="r"><code>    # Predict training data; check overfitting
    ypredCARET.pls.train &lt;- model %&gt;% predict(data.train)

    # Root mean squared error
    RMSE.pls.train = RMSE(yactual.train, ypredCARET.pls.train)
    RMSE.pls.train</code></pre>
<pre><code>## [1] 19.94546</code></pre>
<pre class="r"><code>    # Results in: 13.60

    # Mean absolute error
    MAE.pls.train = MAE(yactual.train, ypredCARET.pls.train)
    MAE.pls.train</code></pre>
<pre><code>## [1] 14.84614</code></pre>
<pre class="r"><code>    # Results in: 10.26

    # Plot ypred vs yactual of training data
    plot(yactual.train, ypredCARET.pls.train,
        xlab=&quot;Observed BP train set&quot;, ylab=&quot;Predicted BP train set&quot;,
        pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main=&quot;Prediction error training set (PLS model)&quot;)
        abline(0,1, col=&#39;red&#39;)
        text(200,ceiling(max(yNN)*1.1),paste(&quot;RMSE: &quot;,RMSE.pls.train))
        text(200,ceiling(max(yNN)*1.1)-50,paste(&quot;MAE: &quot;,MAE.pls.train))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-11-3.png" width="672" /></p>
</div>
<div id="script-block-12-random-forest-model" class="section level4">
<h4>Script block 12: RANDOM FOREST MODEL</h4>
<pre class="r"><code>    # Define training control method; 10 - k - cross validation
    train_control &lt;- trainControl(method=&quot;cv&quot;, number=10)

    # Train the model
    model &lt;- train(y~., data=data.train, trControl=train_control, method=&quot;rf&quot;)

    # Find out what model is best
    print(model)</code></pre>
<pre><code>## Random Forest 
## 
## 106 samples
##  16 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 94, 97, 95, 96, 96, 95, ... 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE      Rsquared   MAE      
##    2    17.69042  0.9945412  10.589629
##    9    16.65938  0.9950118   9.707753
##   16    17.02925  0.9947011   9.839256
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was mtry = 9.</code></pre>
<pre class="r"><code>    # Find out most important variables - BLOCKED - this doesnt work for rf
    if(F){
        Varimportance = varImp(model)
        cat(paste(&quot;Best model fit with&quot;, model$bestTune, &quot;latent components \n&quot;))
        cat(paste(&quot;Latent components:&quot;,paste(rownames(Varimportance$importance)[order(decreasing = T,Varimportance$importance$Overall)][1:model$bestTune[1,]],collapse = &quot;, &quot;),&quot;\n&quot;))
        plot(Varimportance, main=&quot;Varible importance in rf model \n&quot;)
    }
    # Predict test set
    ypredCARET.rf.test &lt;- model %&gt;% predict(data.test)

    # Root mean squared error
    RMSE.rf.test = RMSE(yactual.test, ypredCARET.rf.test)
    RMSE.rf.test</code></pre>
<pre><code>## [1] 8.300245</code></pre>
<pre class="r"><code>    # Results in: 10.61

    # Mean absolute error
    MAE.rf.test = MAE(yactual.test, ypredCARET.rf.test)
    MAE.rf.test</code></pre>
<pre><code>## [1] 5.254375</code></pre>
<pre class="r"><code>    # Results in: 10.00

    # Plot ypred vs yactual of test data
    plot(yactual.test, ypredCARET.rf.test,
        xlab=&quot;Observed BP test set&quot;, ylab=&quot;Predicted BP test set&quot;,
        pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main=&quot;Prediction error test set (RandomForest model)&quot;)
        abline(0,1, col=&#39;red&#39;)
        text(200,ceiling(max(yNN)*1.1),paste(&quot;RMSE: &quot;,RMSE.rf.test))
        text(200,ceiling(max(yNN)*1.1)-50,paste(&quot;MAE: &quot;,MAE.rf.test))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code>    # Predict training data; check overfitting
    ypredCARET.rf.train &lt;- model %&gt;% predict(data.train)

    # Root mean squared error
    RMSE.rf.train = RMSE(yactual.train, ypredCARET.rf.train)
    RMSE.rf.train</code></pre>
<pre><code>## [1] 7.61216</code></pre>
<pre class="r"><code>    # Results in: 13.60

    # Mean absolute error
    MAE.rf.train = MAE(yactual.train, ypredCARET.rf.train)
    MAE.rf.train</code></pre>
<pre><code>## [1] 3.798079</code></pre>
<pre class="r"><code>    # Results in: 10.26

    # Plot ypred vs yactual of training data
    plot(yactual.train, ypredCARET.rf.train,
        xlab=&quot;Observed BP train set&quot;, ylab=&quot;Predicted BP train set&quot;,
        pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main=&quot;Prediction error training set (RandomForest model)&quot;)
        abline(0,1, col=&#39;red&#39;)
        text(200,ceiling(max(yNN)*1.1),paste(&quot;RMSE: &quot;,RMSE.rf.train))
        text(200,ceiling(max(yNN)*1.1)-50,paste(&quot;MAE: &quot;,MAE.rf.train))</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
</div>
<div id="script-block-13" class="section level4">
<h4>Script block 13:</h4>
<pre class="r"><code>print(&quot;the end&quot;)</code></pre>
<pre><code>## [1] &quot;the end&quot;</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
