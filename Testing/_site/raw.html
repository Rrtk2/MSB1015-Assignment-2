<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Raw code</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="version.html">Used packages</a>
</li>
<li>
  <a href="raw.html">Code</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Raw code</h1>

</div>


<pre><code>#-----------------------------------------------------------------------------------------------------#
#       Block 00        GENERAL INFORMATION
#-----------------------------------------------------------------------------------------------------#

# Copyright statement comment:
#   All rights reserved.
#
# Author comment:
#   Rick Reijnders
#   Script version: 29-09-2019

# File description:
#   Name
#     raw R-script.R
#
#   Purpose
#     
#   Inputs
#     
rm(list=ls())
#-----------------------------------------------------------------------------------------------------#
#       Block 01        (Install &amp;) Load packages
#-----------------------------------------------------------------------------------------------------#
# Install packages if needed and load, or just load packages
if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE))
  install.packages(&quot;BiocManager&quot;, ask = F)

# Insert all packages in requiredpackages
requiredpackages &lt;-
  c(&quot;WikidataQueryServiceR&quot;,&quot;ggplot2&quot;,&quot;rJava&quot;,&quot;rcdk&quot;,&quot;pls&quot;,&quot;e1071&quot;,&quot;neuralnet&quot;,&quot;randomForest&quot;,&quot;gplots&quot;,&quot;limma&quot;,&quot;ggfortify&quot;,
    &quot;crayon&quot;)
    
for (i in requiredpackages) {
    if (!requireNamespace(i, quietly = TRUE))
        BiocManager::install(i, ask = F, dependencies = TRUE)
    require(as.character(i), character.only = TRUE)
    print(i)
}

# Set message styles
Confirm.style &lt;- green 
Warning.style &lt;- yellow 
Error.style &lt;- red


cat(Warning.style(&quot;Done running block 01\n&quot;))
cat(Confirm.style(&quot;Starting...\n&quot;))

#-----------------------------------------------------------------------------------------------------#
#       Block 02        SETTINGS
#-----------------------------------------------------------------------------------------------------#
# General settings
options(stringsAsFactors    = F)
Verbose                     = 3     #0-3:   0= no feedback  1= prints results  2=prints results + feedback  3= prints all

# Select 80% for train, 20% for test
Randomfactor = 0.8

# Setting seed to keep consistent results 
set.seed(1)

if(Verbose&gt;=3) cat(Warning.style(&quot;Done running block 02a\n&quot;))

#-----------------------------------------------------------------------------------------------------#
#       Block 03        FUNCTIONS
#-----------------------------------------------------------------------------------------------------#

# Root Mean Squared Error
RMSE = function(yact, ypred){
  sqrt(mean((yact - ypred)^2))
}

# Mean Absolute Error 
MAE = function(yact, ypred){
  mean(abs(yact - ypred))
}


#-----------------------------------------------------------------------------------------------------#
#       Block 03        Get query results
#-----------------------------------------------------------------------------------------------------#
endpoint = &quot;https://query.wikidata.org/bigdata/namespace/wdq/sparql&quot;

query = &#39;SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnitLabel ?CC WHERE {
  ?comp wdt:P31/wdt:P279* wd:Q41581 ;
        p:P2102 [
          ps:P2102 ?bp ;
          psv:P2102/wikibase:quantityUnit  ?bpUnit
        ] .
        ?comp wdt:P233 ?CC .
  SERVICE wikibase:label { bd:serviceParam wikibase:language &quot;[AUTO_LANGUAGE],en&quot;. }
}
&#39;

dataObj = query_wikidata(query)

#-----------------------------------------------------------------------------------------------------#
#       Block 03        bp check ; to kelvin
#-----------------------------------------------------------------------------------------------------#
#C to Kelvin:
# 0°C + 273.15 = 273,15K
idC = which(dataObj$bpUnitLabel==&quot;degree Celsius&quot;)
for( i in 1:length(idC)){
dataObj[idC[i],]$bp = (dataObj[idC[i],]$bp + 273.15)
dataObj[idC[i],]$bpUnitLabel = &quot;kelvin&quot;
}

#F to Kelvin:
# (0°F − 32) × 5/9 + 273.15 = 255,372K
idF = which(dataObj$bpUnitLabel==&quot;degree Fahrenheit&quot;)
for( i in 1:length(idF)){
dataObj[idF[i],]$bp= (dataObj[idF[i],]$bp - 32) * (5/9) + 273.15
dataObj[idF[i],]$bpUnitLabel = &quot;kelvin&quot;
}

#additional failsafe if other metrics than Celsius and Fahrenheit are added (other metrics are removed)
dataObj = dataObj[which(dataObj$bpUnitLabel==&quot;kelvin&quot;),]

# Make backup
dataObjBACKUP = dataObj

# Finalize data structure
dataObj = data.frame(dataObjBACKUP$compLabel, dataObjBACKUP$bp, dataObjBACKUP$CC)
names(dataObj) = c(&quot;Comp&quot;,&quot;bp&quot;,&quot;CC&quot;)
#-----------------------------------------------------------------------------------------------------#
#                           TEST FILTER TO GET LINEAR ALKANES
#-----------------------------------------------------------------------------------------------------#

dataObj = dataObj[-grep(pattern = &quot;\\(&quot;,x = dataObj$CC),]

#-----------------------------------------------------------------------------------------------------#
#       Block 03        OUTLIER TESTING
#-----------------------------------------------------------------------------------------------------#
# hexatriacontane 770.15 K (497 C); in wikidata under pressurised condition!
dataObj$bp[dataObj$Comp==&quot;hexatriacontane&quot;] = 770.15

# Dooctacontane 958.05 K (684.9 c); IN WIKIDATA AS 881.85 k
dataObj$bp[dataObj$Comp==&quot;Dooctacontane&quot;] = 958.05

#-----------------------------------------------------------------------------------------------------#
#       Block 03        DATA VISZ
#-----------------------------------------------------------------------------------------------------#
# Get a general idea of how the data looks; disregarding branch effects; amount of C in compound linked to BP
CClength_crude = nchar(gsub(pattern = &quot;\\)&quot;,replacement = &quot;&quot;,x = gsub(pattern = &quot;\\(&quot;,replacement = &quot;&quot;,x = dataObj$CC)))
plotCClength = CClength_crude[order(CClength_crude)]
BPplot = dataObj$bp[order(CClength_crude)]

# Should result in a exponential function-like graph
plot(plotCClength,BPplot)





#-----------------------------------------------------------------------------------------------------#
#       Block 03        rcdk data extraction see:https://cran.r-project.org/web/packages/rcdk/vignettes/molform.html
#-----------------------------------------------------------------------------------------------------#

sp &lt;- get.smiles.parser()
dc &lt;- get.desc.categories()

for( i in 1:length(dataObj$CC)){

    # Get smiles from result query and add information
    molecule &lt;- parse.smiles(dataObj$CC[i])[[1]]
    convert.implicit.to.explicit(molecule)
    #formula &lt;- get.mol2formula(molecule,charge=0)


    # Store the found information
    #dataObj$formula[i] = {formula} # S4 object cannot be transferred nicely
    #dataObj$mass[i] = formula@mass
    #dataObj$string[i] = formula@string
    #dataObj$charge[i] = formula@charge

    # M/z values 
    #dataObj$isotopes[i] = {get.isotopes.pattern(formula,minAbund=0.1)}

    # Fingerprint? values
    #dataObj$fingerprint[i] = {get.fingerprint(molecule = molecule)}

    # Create a dataframe which contains all info possible to extract using the descriptors
    datafr = dataObj$Comp[i]
    for(o in 1:5){
        dn &lt;- get.desc.names(dc[o])
        datafr = cbind(datafr, eval.desc(molecule, dn))
    }
    
    # This is done now as it will break if descriptors change (amount)
    if(exists(&quot;mydata&quot;)){
        mydata[i,] = datafr
        }else{
        mydata = datafr
    }

}

# Make backup from data, easy for testing (resetting)
mydataBACKUP = mydata
mydata = mydataBACKUP

# Remove names
descs = mydata[,-1]


#-----------------------------------------------------------------------------------------------------#
#                           Latent variable selection (correlation)
#-----------------------------------------------------------------------------------------------------#
# Remove NAs n stuff
descs &lt;- descs[, !apply(descs, 2, function(x) any(is.na(x)) )]
descs &lt;- descs[, !apply( descs, 2, function(x) length(unique(x)) == 1 )]

# Correlate the descriptors with the boiling point; if these are linked, they should add some info
corMatrix = cor(descs , dataObj$bp)
corMatrix = as.data.frame(corMatrix[order(abs(corMatrix),decreasing = T),])

# select first 15 components:
componentNames = rownames(corMatrix)[1:15]
descs = descs[,match(colnames(descs), x = componentNames)]



# Old method, keepin this inside for further reference
if(F){
    mydata = mydataBACKUP

    descs = mydata[,-1]


    # crude way to extract &#39;important&#39; features based on correlation
    descs &lt;- descs[, !apply(descs, 2, function(x) any(is.na(x)) )]
    descs &lt;- descs[, !apply( descs, 2, function(x) length(unique(x)) == 1 )]
    r2 &lt;- which(cor(descs)^2 &gt; .9, arr.ind=TRUE) # when keeping this high, the prediction improves
    r2 &lt;- r2[ r2[,1] &gt; r2[,2] , ]
    descs &lt;- descs[, -unique(r2[,2])]
}

# should contain nAtomLAC; the amount of c atoms
if(!exists(&quot;descs$nAtomLAC&quot;)){

    descs = cbind(descs, mydata$nAtomLAC)
    names(descs)[dim(descs)[2]] = &quot;n&quot;
    }else{
    names(descs)[names(descs)==&quot;descs$nAtomLAC&quot;] = &quot;n&quot;
}

# add parameters from paper!

#descs$w = 1/6*(descs$n-1)*(descs$n)*(descs$n+1)
#descs$p = descs$n - 3
# the folowing screw up the analysis:
#descs$A = 98/descs$n^2 * descs$w
#descs$B = 5.5*descs$p

# store resulting input file in my_data; as it is used everywhere
my_data = descs

#-----------------------------------------------------------------------------
#Finish prepare data
#-----------------------------------------------------------------------------
# Add and define the &#39;to be predicted&#39; column
n_col &lt;- ncol(my_data)
BoilPoint = n_col+1
my_data[,BoilPoint] = dataObj$bp
names(my_data)[BoilPoint] = &#39;BoilPoint&#39;



#-----------------------------------------------------------------------------------------------------#
#                           MACHINE LEARINGN
#-----------------------------------------------------------------------------------------------------#

#-----------------------------------------------------------------------------------------------------#
#               Data subsetting; Train; Test
#-----------------------------------------------------------------------------------------------------#
# ceiling(dim(my_data)[1]0.8)
#make data objects
samples.upper = sample(length(my_data[,1]), floor(length(my_data[,1])*Randomfactor))  #get all unique samples (not frequecies) and sample 80%
samples.total = (1:length(my_data[,1])) # all unique samples (not frequecies)
samples.lowerl = samples.total[!samples.total %in% samples.upper]  #which samples are sampled
data.train = my_data[samples.upper,]#contains all upper logical
data.train = as.data.frame(data.train)

#data.train = t(data.train)
data.test = my_data[samples.lowerl,]#contains all lower logical
data.test = as.data.frame(data.test)
#data.test = t(data.test)

# NOTE: annotations are within location [,32007]
data.train[,BoilPoint] = data.train[,BoilPoint]
data.test[,BoilPoint] = data.test[,BoilPoint]

#remove nas
data.train=data.train[!is.na(data.train[,1]),]
data.test=data.test[!is.na(data.test[,1]),]
set.seed(123)


xNN = data.train[,-(BoilPoint)]
yNN = data.train[,BoilPoint]

dat = data.frame(xNN, y = yNN)
#yactual = data.test[,BoilPoint]
yactual.test = data.test[,BoilPoint]
yactual.train = data.train[,BoilPoint]

#-----------------------------------------------------------------------------------------------------#
#                           PLS MODEL VALIDATION NOT RUNNING ATM!
#-----------------------------------------------------------------------------------------------------#
#NOT RUNNING ATM! 
if(F){

# so the model from the paper https://pubs.acs.org/doi/abs/10.1021/ja01193a005 is:
# tB = aw + bp + c
# a = constant
# b = constant
# c = constant
# p = polarity number
# w = sum of dist; number of carbonatoms to left multiply by remaining right; use all bounds

# resulted formula:  t = 98/n^2 * w + 5.5*p
# w = 1/6*(n-1)*(n)*(n+1)
# p = n - 3

# Rephrased formula:  t = A + B
# A = 98/n^2 * w
# B = 5.5*p
# w = 1/6*(n-1)*(n)*(n+1)
# p = n - 3


datPLS = dat
datPLS$w = 1/6*(datPLS$n-1)*(datPLS$n)*(datPLS$n+1)
datPLS$p = datPLS$n - 3
datPLS$A = 98/datPLS$n^2 * datPLS$w
datPLS$B = 5.5*datPLS$p

data.testPLS = data.test
data.testPLS$w = 1/6*(data.test$n-1)*(data.test$n)*(data.test$n+1)
data.testPLS$p = data.test$n - 3
data.testPLS$A = 98/data.testPLS$n^2 * data.testPLS$w
data.testPLS$B = 5.5*data.testPLS$p

# PLS MODEL
PLSfit = plsr(y ~ A + B, data = datPLS, validation = &quot;LOO&quot;)


# Select amount of components
ncomp.onesigma &lt;- selectNcomp(PLSfit, method = &quot;onesigma&quot;, plot = TRUE)
ncomp.permut &lt;- selectNcomp(PLSfit, method = &quot;randomization&quot;, plot = TRUE)

# If methods doubt between 5 or 7 components, take the highest rounded mean (6).
PLSfit = plsr(y ~ ., ncomp = ceiling(mean(ncomp.onesigma,ncomp.permut)), data = datPLS, validation = &quot;LOO&quot;)

#so put data.predicted and actual data.test together
ypredPLS = predict(PLSfit, as.data.frame(data.testPLS[,-(BoilPoint)]),type=&quot;response&quot;)

# Root mean squared error
RMSE(yactual, ypredPLS)
#   Results in: 53.59

# Mean absolute error
MAE(yactual, ypredPLS)
#   Results in: 39.25

}

#-----------------------------------------------------------------------------------------------------#
#                           Linear Regression (exponential)
#-----------------------------------------------------------------------------------------------------#

# Glm! uses the 15 components 
GLMfit = glm(y ~ ., dat,family = Gamma(link=&quot;log&quot;))

#so put data.predicted and actual data.test together
ypredGLM.test = predict(GLMfit, as.data.frame(data.test[,-(BoilPoint)]),type=&quot;response&quot;)


# Root mean squared error
RMSE(yactual.test, ypredGLM.test)
#   Results in: 36.76

# Mean absolute error
MAE(yactual.test, ypredGLM.test)
#   Results in: 22.11

plot(yactual.test, ypredGLM.test,
     xlab=&quot;Observed BP test set&quot;, ylab=&quot;Predicted BP test set&quot;,
     pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)))
abline(0,1, col=&#39;red&#39;)



### Train set; over/underfitting ###
ypredGLM.train = predict(GLMfit, as.data.frame(data.train[,-(BoilPoint)]),type=&quot;response&quot;)
yactual.train = data.train[,BoilPoint]

# Root mean squared error
RMSE(data.train[,(BoilPoint)], ypredGLM.train)
#   Results in: 23.32

# Mean absolute error
MAE(data.train[,(BoilPoint)], ypredGLM.train)
#   Results in: 7.844

plot(yactual.train, ypredGLM.train,
     xlab=&quot;Observed BP train set&quot;, ylab=&quot;Predicted BP train set&quot;,
     pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)))
abline(0,1, col=&#39;red&#39;)


#-----------------------------------------------------------------------------------------------------#
#                           Linear Regression
#-----------------------------------------------------------------------------------------------------#


# S3 method for formula
PLSfit = plsr(y ~ ., data = dat,family = Gamma(link=&quot;log&quot;), validation = &quot;LOO&quot;)

# Select amount of components
ncomp.onesigma &lt;- selectNcomp(PLSfit, method = &quot;onesigma&quot;, plot = TRUE)
ncomp.permut &lt;- selectNcomp(PLSfit, method = &quot;randomization&quot;, plot = TRUE)

# If methods doubt between 5 or 7 components, take the highest rounded mean (6).
PLSfit = plsr(y ~ ., ncomp = ceiling(mean(ncomp.onesigma,ncomp.permut)), data = dat, validation = &quot;LOO&quot;)

#so put data.predicted and actual data.test together
ypredPLS.test = predict(PLSfit, as.data.frame(data.test[,-(BoilPoint)]),type=&quot;response&quot;)

# Root mean squared error
RMSE(yactual.test, ypredPLS.test)
#   Results in: 53.59

# Mean absolute error
MAE(yactual.test, ypredPLS.test)
#   Results in: 39.25


plot(yactual.test, ypredPLS.test[,,dim(ypredPLS.test)[3]],
     xlab=&quot;Observed BP test set&quot;, ylab=&quot;Predicted BP test set&quot;,
     pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)))
abline(0,1, col=&#39;red&#39;)


### Train set; over/underfitting ###

#so put data.predicted and actual data.test together
ypredPLS.train = predict(PLSfit, as.data.frame(data.train[,-(BoilPoint)]),type=&quot;response&quot;)

# Root mean squared error
RMSE(yactual.train, ypredPLS.train)
#   Results in: 53.59

# Mean absolute error
MAE(yactual.train, ypredPLS.train)
#   Results in: 39.25


plot(yactual.train, ypredPLS.train[,,dim(ypredPLS.train)[3]],
     xlab=&quot;Observed BP train set&quot;, ylab=&quot;Predicted BP train set&quot;,
     pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)))
abline(0,1, col=&#39;red&#39;)


#-----------------------------------------------------------------------------------------------------#
#                                       RF
#-----------------------------------------------------------------------------------------------------#


prot.rf &lt;- randomForest(y ~ ., importance=TRUE, proximity=TRUE,data=dat, ntree=200)

# after building the random forest, now we apply it on the test dataset
ypredRF.test &lt;- predict(prot.rf, data.test[,-(BoilPoint)])


# Root mean squared error
RMSE(yactual.test, ypredRF.test)
#   Results in: 20.26

# Mean absolute error
MAE(yactual.test, ypredRF.test)
#   Results in: 7.63




# after building the random forest, now we apply it on the test dataset
ypredRF.train &lt;- predict(prot.rf, data.train[,-(BoilPoint)])


# Root mean squared error
RMSE(yactual.train, ypredRF.train)
#   Results in: 20.26

# Mean absolute error
MAE(yactual.train, ypredRF.train)
#   Results in: 7.63</code></pre>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
